{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0412cca46b404a85be89e45f96f93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62e932531c44c9dbd6e2f44a3669f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e84e9cd5404c4c8cca76e5953a4253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f6f36ac699407bbefe2418d44173b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca593e2736a4dde866854caefa1c51f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5dbf2c49d464d43ae7a59920d30ee51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8158a3f4ea3a44648c5f07a62290e776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03df58fe52e46eeb8964967781b23a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da86d2cff4cf42d49d5ed122e1a9c9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db2b776dabf4c3098ab0c543baa2c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_dir = './Lip_frameByFrame/ABSOLUTELY/ABSOLUTELY_000'\n",
    "k = 0\n",
    "n_class = 10\n",
    "n_sample_per_class = 10\n",
    "n_samples = n_class*n_sample_per_class\n",
    "X_train = np.zeros((n_samples, 29, 50*100))\n",
    "for i in tqdm(range(82,92)):\n",
    "    for j in range(29):\n",
    "        img = plt.imread(data_dir+str(i)+'.mp4/standard/typeIII/Frame'+str(j)+'_Type3_standard.jpg')\n",
    "        gray_img = 0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2]\n",
    "        img_v = np.reshape(gray_img,(gray_img.shape[0]*gray_img.shape[1]))\n",
    "        X_train[k, j, :] = img_v\n",
    "    k +=1\n",
    "    \n",
    "data_dir = './Lip_frameByFrame/ACCESS/ACCESS_000'\n",
    "for i in tqdm(range(10,20)):\n",
    "    for j in range(29):\n",
    "        img = plt.imread(data_dir+str(i)+'.mp4/standard/typeIII/Frame'+str(j)+'_Type3_standard.jpg')\n",
    "        gray_img = 0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2]\n",
    "        img_v = np.reshape(gray_img,(gray_img.shape[0]*gray_img.shape[1]))\n",
    "        X_train[k, j, :] = img_v\n",
    "    k +=1\n",
    "data_dir = './Lip_frameByFrame/ACTUALLY/ACTUALLY_000'\n",
    "for i in tqdm(range(60,70)):\n",
    "    for j in range(29):\n",
    "        img = plt.imread(data_dir+str(i)+'.mp4/standard/typeIII/Frame'+str(j)+'_Type3_standard.jpg')\n",
    "        gray_img = 0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2]\n",
    "        img_v = np.reshape(gray_img,(gray_img.shape[0]*gray_img.shape[1]))\n",
    "        X_train[k, j, :] = img_v\n",
    "    k +=1\n",
    "data_dir = './Lip_frameByFrame/AGAIN/AGAIN_000'\n",
    "for i in tqdm(range(80,90)):\n",
    "    for j in range(29):\n",
    "        img = plt.imread(data_dir+str(i)+'.mp4/standard/typeIII/Frame'+str(j)+'_Type3_standard.jpg')\n",
    "        gray_img = 0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2]\n",
    "        img_v = np.reshape(gray_img,(gray_img.shape[0]*gray_img.shape[1]))\n",
    "        X_train[k, j, :] = img_v\n",
    "    k +=1\n",
    "data_dir = './Lip_frameByFrame/AHEAD/AHEAD_000'\n",
    "for i in tqdm(range(80,90)):\n",
    "    for j in range(29):\n",
    "        img = plt.imread(data_dir+str(i)+'.mp4/standard/typeIII/Frame'+str(j)+'_Type3_standard.jpg')\n",
    "        gray_img = 0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2]\n",
    "        img_v = np.reshape(gray_img,(gray_img.shape[0]*gray_img.shape[1]))\n",
    "        X_train[k, j, :] = img_v\n",
    "    k +=1\n",
    "data_dir = './Lip_frameByFrame/ALLOW/ALLOW_000'\n",
    "for i in tqdm(range(80,90)):\n",
    "    for j in range(29):\n",
    "        img = plt.imread(data_dir+str(i)+'.mp4/standard/typeIII/Frame'+str(j)+'_Type3_standard.jpg')\n",
    "        gray_img = 0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2]\n",
    "        img_v = np.reshape(gray_img,(gray_img.shape[0]*gray_img.shape[1]))\n",
    "        X_train[k, j, :] = img_v\n",
    "    k +=1\n",
    "data_dir = './Lip_frameByFrame/ALWAYS/ALWAYS_00'\n",
    "for i in tqdm(range(167,177)):\n",
    "    for j in range(29):\n",
    "        img = plt.imread(data_dir+str(i)+'.mp4/standard/typeIII/Frame'+str(j)+'_Type3_standard.jpg')\n",
    "        gray_img = 0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2]\n",
    "        img_v = np.reshape(gray_img,(gray_img.shape[0]*gray_img.shape[1]))\n",
    "        X_train[k, j, :] = img_v\n",
    "    k +=1\n",
    "data_dir = './Lip_frameByFrame/AMERICA/AMERICA_000'\n",
    "for i in tqdm(range(31,41)):\n",
    "    for j in range(29):\n",
    "        img = plt.imread(data_dir+str(i)+'.mp4/standard/typeIII/Frame'+str(j)+'_Type3_standard.jpg')\n",
    "        gray_img = 0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2]\n",
    "        img_v = np.reshape(gray_img,(gray_img.shape[0]*gray_img.shape[1]))\n",
    "        X_train[k, j, :] = img_v\n",
    "    k +=1\n",
    "data_dir = './Lip_frameByFrame/ANSWER/ANSWER_000'\n",
    "for i in tqdm(range(61,71)):\n",
    "    for j in range(29):\n",
    "        img = plt.imread(data_dir+str(i)+'.mp4/standard/typeIII/Frame'+str(j)+'_Type3_standard.jpg')\n",
    "        gray_img = 0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2]\n",
    "        img_v = np.reshape(gray_img,(gray_img.shape[0]*gray_img.shape[1]))\n",
    "        X_train[k, j, :] = img_v\n",
    "    k +=1\n",
    "data_dir = './Lip_frameByFrame/AROUND/AROUND_000'\n",
    "for i in tqdm(range(50,60)):\n",
    "    for j in range(29):\n",
    "        img = plt.imread(data_dir+str(i)+'.mp4/standard/typeIII/Frame'+str(j)+'_Type3_standard.jpg')\n",
    "        gray_img = 0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2]\n",
    "        img_v = np.reshape(gray_img,(gray_img.shape[0]*gray_img.shape[1]))\n",
    "        X_train[k, j, :] = img_v\n",
    "    k +=1\n",
    "    \n",
    "y_train = np.reshape(np.array([np.zeros(10), np.ones(10), 2*np.ones(10), 3*np.ones(10),\n",
    "          4*np.ones(10), 5*np.ones(10), 6*np.ones(10), 7*np.ones(10),\n",
    "          8*np.ones(10), 9*np.ones(10)]),(n_class*n_sample_per_class,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf584c103c8f4de886d7276e1bbbbe24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d409f000b0fa4e869016bf1895a23240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8056761bdde4260bd9bf8dbf9bf0e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ccfd7c639142a18b13ad559b469fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ef1fd70e7242f5b60bce6277296c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04870c7616414db59f80ca9389f887bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d8d13eb6344fb0a58d4f80d0547907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1901e309dd40d0a121367ceee98425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f8524c6dc2457e9ca03d49f714175c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd620f47cc64e1a9776d62896288370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_dir = './Lip_frameByFrame/ABSOLUTELY/ABSOLUTELY_0000'\n",
    "k = 0\n",
    "n_class = 10\n",
    "n_sample_per_class = 5\n",
    "n_samples = n_class*n_sample_per_class\n",
    "X_test = np.zeros((n_samples, 29, 50*100))\n",
    "for i in tqdm(range(2,7)):\n",
    "    for j in range(29):\n",
    "        img = plt.imread(data_dir+str(i)+'.mp4/standard/typeIII/Frame'+str(j)+'_Type3_standard.jpg')\n",
    "        gray_img = 0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2]\n",
    "        img_v = np.reshape(gray_img,(gray_img.shape[0]*gray_img.shape[1]))\n",
    "        X_test[k, j, :] = img_v\n",
    "    k +=1\n",
    "    \n",
    "data_dir = './Lip_frameByFrame/ACCESS/ACCESS_0000'\n",
    "for i in tqdm(range(1,6)):\n",
    "    for j in range(29):\n",
    "        img = plt.imread(data_dir+str(i)+'.mp4/standard/typeIII/Frame'+str(j)+'_Type3_standard.jpg')\n",
    "        gray_img = 0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2]\n",
    "        img_v = np.reshape(gray_img,(gray_img.shape[0]*gray_img.shape[1]))\n",
    "        X_test[k, j, :] = img_v\n",
    "    k +=1\n",
    "data_dir = './Lip_frameByFrame/ACTUALLY/ACTUALLY_0000'\n",
    "for i in tqdm(range(2,7)):\n",
    "    for j in range(29):\n",
    "        img = plt.imread(data_dir+str(i)+'.mp4/standard/typeIII/Frame'+str(j)+'_Type3_standard.jpg')\n",
    "        gray_img = 0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2]\n",
    "        img_v = np.reshape(gray_img,(gray_img.shape[0]*gray_img.shape[1]))\n",
    "        X_test[k, j, :] = img_v\n",
    "    k +=1\n",
    "data_dir = './Lip_frameByFrame/AGAIN/AGAIN_000'\n",
    "for i in tqdm(range(15,20)):\n",
    "    for j in range(29):\n",
    "        img = plt.imread(data_dir+str(i)+'.mp4/standard/typeIII/Frame'+str(j)+'_Type3_standard.jpg')\n",
    "        gray_img = 0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2]\n",
    "        img_v = np.reshape(gray_img,(gray_img.shape[0]*gray_img.shape[1]))\n",
    "        X_test[k, j, :] = img_v\n",
    "    k +=1\n",
    "data_dir = './Lip_frameByFrame/AHEAD/AHEAD_0000'\n",
    "for i in tqdm(range(2,7)):\n",
    "    for j in range(29):\n",
    "        img = plt.imread(data_dir+str(i)+'.mp4/standard/typeIII/Frame'+str(j)+'_Type3_standard.jpg')\n",
    "        gray_img = 0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2]\n",
    "        img_v = np.reshape(gray_img,(gray_img.shape[0]*gray_img.shape[1]))\n",
    "        X_test[k, j, :] = img_v\n",
    "    k +=1\n",
    "data_dir = './Lip_frameByFrame/ALLOW/ALLOW_0000'\n",
    "for i in tqdm(range(5,10)):\n",
    "    for j in range(29):\n",
    "        img = plt.imread(data_dir+str(i)+'.mp4/standard/typeIII/Frame'+str(j)+'_Type3_standard.jpg')\n",
    "        gray_img = 0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2]\n",
    "        img_v = np.reshape(gray_img,(gray_img.shape[0]*gray_img.shape[1]))\n",
    "        X_test[k, j, :] = img_v\n",
    "    k +=1\n",
    "data_dir = './Lip_frameByFrame/ALWAYS/ALWAYS_000'\n",
    "for i in tqdm(range(20,25)):\n",
    "    for j in range(29):\n",
    "        img = plt.imread(data_dir+str(i)+'.mp4/standard/typeIII/Frame'+str(j)+'_Type3_standard.jpg')\n",
    "        gray_img = 0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2]\n",
    "        img_v = np.reshape(gray_img,(gray_img.shape[0]*gray_img.shape[1]))\n",
    "        X_test[k, j, :] = img_v\n",
    "    k +=1\n",
    "data_dir = './Lip_frameByFrame/AMERICA/AMERICA_000'\n",
    "for i in tqdm(range(10,15)):\n",
    "    for j in range(29):\n",
    "        img = plt.imread(data_dir+str(i)+'.mp4/standard/typeIII/Frame'+str(j)+'_Type3_standard.jpg')\n",
    "        gray_img = 0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2]\n",
    "        img_v = np.reshape(gray_img,(gray_img.shape[0]*gray_img.shape[1]))\n",
    "        X_test[k, j, :] = img_v\n",
    "    k +=1\n",
    "data_dir = './Lip_frameByFrame/ANSWER/ANSWER_0000'\n",
    "for i in tqdm(range(1,6)):\n",
    "    for j in range(29):\n",
    "        img = plt.imread(data_dir+str(i)+'.mp4/standard/typeIII/Frame'+str(j)+'_Type3_standard.jpg')\n",
    "        gray_img = 0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2]\n",
    "        img_v = np.reshape(gray_img,(gray_img.shape[0]*gray_img.shape[1]))\n",
    "        X_test[k, j, :] = img_v\n",
    "    k +=1\n",
    "data_dir = './Lip_frameByFrame/AROUND/AROUND_0000'\n",
    "for i in tqdm(range(5,10)):\n",
    "    for j in range(29):\n",
    "        img = plt.imread(data_dir+str(i)+'.mp4/standard/typeIII/Frame'+str(j)+'_Type3_standard.jpg')\n",
    "        gray_img = 0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2]\n",
    "        img_v = np.reshape(gray_img,(gray_img.shape[0]*gray_img.shape[1]))\n",
    "        X_test[k, j, :] = img_v\n",
    "    k +=1\n",
    "\n",
    "\n",
    "y_test = np.reshape(np.array([np.zeros(n_sample_per_class), np.ones(n_sample_per_class),\n",
    "                              2*np.ones(n_sample_per_class), 3*np.ones(n_sample_per_class),\n",
    "                              4*np.ones(n_sample_per_class), 5*np.ones(n_sample_per_class),\n",
    "                              6*np.ones(n_sample_per_class), 7*np.ones(n_sample_per_class),\n",
    "                              8*np.ones(n_sample_per_class), 9*np.ones(n_sample_per_class)]),\n",
    "                    (n_class*n_sample_per_class,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden\n",
    "\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.lstm(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden\n",
    "    \n",
    "def train(train_loader, learn_rate, hidden_dim=256, EPOCHS=5, model_type=\"GRU\"):\n",
    "    \n",
    "    # Setting common hyperparameters\n",
    "    input_dim = next(iter(train_loader))[0].shape[2]\n",
    "    output_dim = 1\n",
    "    n_layers = 2\n",
    "    # Instantiating the models\n",
    "    if model_type == \"GRU\":\n",
    "        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    else:\n",
    "        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Defining loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    \n",
    "    model.train()\n",
    "    print(\"Starting Training of {} model\".format(model_type))\n",
    "    epoch_times = []\n",
    "    # Start training loop\n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "#         start_time = time.clock()\n",
    "        h = model.init_hidden(batch_size)\n",
    "        avg_loss = 0.\n",
    "        counter = 0\n",
    "        for x, label in train_loader:\n",
    "            counter += 1\n",
    "            if model_type == \"GRU\":\n",
    "                h = h.data\n",
    "            else:\n",
    "                h = tuple([e.data for e in h])\n",
    "            model.zero_grad()\n",
    "            \n",
    "            out, h = model(x.to(device).float(), h)\n",
    "            loss = criterion(out, label.to(device).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "            if counter%200 == 0:\n",
    "                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter, len(train_loader), avg_loss/counter))\n",
    "#         current_time = time.clock()\n",
    "        print(\"Epoch {}/{} Done, Total Loss: {}\".format(epoch, EPOCHS, avg_loss/len(train_loader)))\n",
    "#         print(\"Total Time Elapsed: {} seconds\".format(str(current_time-start_time)))\n",
    "#         epoch_times.append(current_time-start_time)\n",
    "#     print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n",
    "    return model\n",
    "\n",
    "def evaluate(model, test_x, test_y, label_scalers):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []\n",
    "#     start_time = time.clock()\n",
    "\n",
    "    inp = torch.from_numpy(np.array(test_x))\n",
    "    labs = torch.from_numpy(np.array(test_y))\n",
    "    h = model.init_hidden(inp.shape[0])\n",
    "    out, h = model(inp.to(device).float(), h)\n",
    "    outputs = out.cpu().detach().numpy()\n",
    "#     print(\"Evaluation Time: {}\".format(str(time.clock()-start_time)))\n",
    "    sMAPE = 0\n",
    "    for i in range(len(outputs)):\n",
    "        sMAPE += np.mean(abs(outputs[i]-test_y[i])/(test_y[i]+outputs[i])/2)/len(outputs)\n",
    "    print(\"error: {}%\".format(sMAPE*100))\n",
    "    return outputs, test_y, sMAPE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training of GRU model\n",
      "Epoch 1/5 Done, Total Loss: 11.3704909324646\n",
      "Epoch 2/5 Done, Total Loss: 8.184114694595337\n",
      "Epoch 3/5 Done, Total Loss: 9.486515522003174\n",
      "Epoch 4/5 Done, Total Loss: 8.84829306602478\n",
      "Epoch 5/5 Done, Total Loss: 8.660684537887573\n",
      "Starting Training of LSTM model\n",
      "Epoch 1/5 Done, Total Loss: 9.771764469146728\n",
      "Epoch 2/5 Done, Total Loss: 8.439128303527832\n",
      "Epoch 3/5 Done, Total Loss: 8.367644929885865\n",
      "Epoch 4/5 Done, Total Loss: 8.703034400939941\n",
      "Epoch 5/5 Done, Total Loss: 8.566537189483643\n",
      "error: 17.350763237700725%\n",
      "error: 16.500098228600645%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "lr = 0.01\n",
    "gru_model = train(train_loader, lr, model_type=\"GRU\")\n",
    "Lstm_model = train(train_loader, lr, model_type=\"LSTM\")\n",
    "\n",
    "gru_outputs, targets, gru_sMAPE = evaluate(gru_model, X_test, y_test, [])\n",
    "lstm_outputs, targets, lstm_sMAPE = evaluate(Lstm_model, X_test, y_test, [])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
